{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf334f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to vowel_formant_features.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extract_vowel_from_filename(filename):\n",
    "    match = re.search(r'[a-zA-Z]', filename)\n",
    "    if match:\n",
    "        return match.group().lower()\n",
    "    return None\n",
    "\n",
    "def process_folder(input_folder, output_csv, sampling_rate=16000):\n",
    "    data = []\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            samples = read_samples_from_txt(file_path)\n",
    "            \n",
    "            lpcas = extract_plp_features(samples, sampling_rate=sampling_rate)\n",
    "            if lpcas is None:\n",
    "                continue\n",
    "\n",
    "            w, h = compute_lpc_filter_and_response(lpcas)\n",
    "\n",
    "            formant_1_w, formant_2_w = find_formants_across_frames(w, h)\n",
    "\n",
    "            # Convert to Hertz\n",
    "            formant_1_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_1_w]\n",
    "            formant_2_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_2_w]\n",
    "\n",
    "            vowel = extract_vowel_from_filename(filename)\n",
    "            if vowel is None:\n",
    "                print(f\"Could not extract vowel from {filename}\")\n",
    "                continue\n",
    "\n",
    "            # Prepare data for CSV\n",
    "            for f1, f2 in zip(formant_1_Hz, formant_2_Hz):\n",
    "                if f1 is not None and f2 is not None:\n",
    "                    data.append([f1, f2, vowel])\n",
    "    \n",
    "    # Save data to CSV\n",
    "    df = pd.DataFrame(data, columns=['Formant_1_Hz', 'Formant_2_Hz', 'Vowel'])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Features saved to {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "input_folder = r\"Vowel_recordings\"\n",
    "output_csv = r\"vowel_formant_features.csv\"\n",
    "process_folder(input_folder, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21081d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score: 0.4432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(output_csv)\n",
    "\n",
    "# Encode vowel labels\n",
    "le = LabelEncoder()\n",
    "df['Vowel_Encoded'] = le.fit_transform(df['Vowel'])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = df[['Formant_1_Hz', 'Formant_2_Hz']]\n",
    "y = df['Vowel_Encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest Regressor\n",
    "rfr = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "score = rfr.score(X_test, y_test)\n",
    "print(f\"Model score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c89cccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to vowel_formant_features.csv\n",
      "Train accuracy: 0.95\n",
      "Test accuracy: 0.74\n",
      "Cross-validation accuracy: 0.72 (+/- 0.03)\n",
      "Predicted vowels saved to predicted_vowels.csv\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from scipy.signal import freqz\n",
    "import peakutils\n",
    "from sidekit.frontend.features import plp\n",
    "\n",
    "def read_samples_from_txt(file_path):\n",
    "    samples = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            samples.extend([float(value) for value in line.strip().split()])\n",
    "    return np.array(samples)\n",
    "\n",
    "def extract_plp_features(samples, sampling_rate=16000, rasta=False, plp_order=10):\n",
    "    try:\n",
    "        lpcas = plp(samples, fs=sampling_rate, rasta=rasta, plp_order=plp_order)\n",
    "        return lpcas\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting PLP features: {e}\")\n",
    "        return None\n",
    "\n",
    "def compute_lpc_filter_and_response(lpc_coeffs):\n",
    "    if lpc_coeffs is None:\n",
    "        raise ValueError(\"LPC coefficients are not provided.\")\n",
    "    \n",
    "    if isinstance(lpc_coeffs, (list, np.ndarray)):\n",
    "        lpc_coeffs = np.array(lpc_coeffs)\n",
    "        if lpc_coeffs.ndim != 2:\n",
    "            raise ValueError(\"LPC coefficients must be a 2D array (frames x order).\")\n",
    "    \n",
    "    num_frames, num_order = lpc_coeffs.shape\n",
    "    all_w = []\n",
    "    all_h = []\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        lpc_filter = np.concatenate(([1], -lpc_coeffs[i]))\n",
    "        w, h = freqz(lpc_filter)\n",
    "        all_w.append(w)\n",
    "        all_h.append(h)\n",
    "    \n",
    "    all_w = np.array(all_w)\n",
    "    all_h = np.array(all_h)\n",
    "    \n",
    "    return all_w, all_h\n",
    "\n",
    "def find_formants_across_frames(w, h):\n",
    "    formant_1_w = []\n",
    "    formant_2_w = []\n",
    "    formant_3_w = []\n",
    "    \n",
    "    for i in range(w.shape[0]):\n",
    "        h_db = 20 * np.log10(np.abs(h[i]))\n",
    "        peak_indices = peakutils.indexes(h_db)\n",
    "\n",
    "        if peak_indices.size > 2:\n",
    "            formant_1_w.append(w[i][peak_indices[0]])\n",
    "            formant_2_w.append(w[i][peak_indices[1]])\n",
    "            formant_3_w.append(w[i][peak_indices[2]])\n",
    "        else:\n",
    "            formant_1_w.append(None)\n",
    "            formant_2_w.append(None)\n",
    "            formant_3_w.append(None)\n",
    "    \n",
    "    return formant_1_w, formant_2_w, formant_3_w\n",
    "\n",
    "def extract_vowel_from_filename(filename):\n",
    "    match = re.search(r'[a-zA-Z]', filename)\n",
    "    if match:\n",
    "        return match.group().lower()\n",
    "    return None\n",
    "\n",
    "def process_folder(input_folder, output_csv, sampling_rate=16000):\n",
    "    data = []\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            samples = read_samples_from_txt(file_path)\n",
    "            \n",
    "            lpcas = extract_plp_features(samples, sampling_rate=sampling_rate)\n",
    "            if lpcas is None:\n",
    "                continue\n",
    "\n",
    "            w, h = compute_lpc_filter_and_response(lpcas)\n",
    "\n",
    "            formant_1_w, formant_2_w, formant_3_w = find_formants_across_frames(w, h)\n",
    "\n",
    "            formant_1_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_1_w]\n",
    "            formant_2_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_2_w]\n",
    "            formant_3_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_3_w]\n",
    "\n",
    "            vowel = extract_vowel_from_filename(filename)\n",
    "            if vowel is None:\n",
    "                print(f\"Could not extract vowel from {filename}\")\n",
    "                continue\n",
    "\n",
    "            for f1, f2, f3 in zip(formant_1_Hz, formant_2_Hz, formant_3_Hz):\n",
    "                if f1 is not None and f2 is not None and f3 is not None:\n",
    "                    data.append([f1, f2, f3, vowel])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['Formant_1_Hz', 'Formant_2_Hz', 'Formant_3_Hz', 'Vowel'])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Features saved to {output_csv}\")\n",
    "\n",
    "def train_random_forest(output_csv):\n",
    "    df = pd.read_csv(output_csv)\n",
    "    le = LabelEncoder()\n",
    "    df['Vowel_Encoded'] = le.fit_transform(df['Vowel'])\n",
    "    X = df[['Formant_1_Hz', 'Formant_2_Hz', 'Formant_3_Hz']]\n",
    "    y = df['Vowel_Encoded']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Using the given hyperparameters directly\n",
    "    best_params = {\n",
    "        'max_depth': 20,\n",
    "        'max_features': 'auto',\n",
    "        'min_samples_leaf': 1,\n",
    "        'min_samples_split': 5,\n",
    "        'n_estimators': 100\n",
    "    }\n",
    "\n",
    "    rfc = RandomForestClassifier(random_state=42, **best_params)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model performance\n",
    "    train_accuracy = rfc.score(X_train, y_train)\n",
    "    test_accuracy = rfc.score(X_test, y_test)\n",
    "    print(f\"Train accuracy: {train_accuracy:.2f}\")\n",
    "    print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(rfc, X, y, cv=5)\n",
    "    print(f\"Cross-validation accuracy: {cv_scores.mean():.2f} (+/- {cv_scores.std():.2f})\")\n",
    "\n",
    "    return rfc, le\n",
    "\n",
    "def classify_files(input_folder, model, le, sampling_rate=16000, output_csv=\"predicted_vowels.csv\"):\n",
    "    results = []\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            samples = read_samples_from_txt(file_path)\n",
    "            \n",
    "            lpcas = extract_plp_features(samples, sampling_rate=sampling_rate)\n",
    "            if lpcas is None:\n",
    "                continue\n",
    "\n",
    "            w, h = compute_lpc_filter_and_response(lpcas)\n",
    "\n",
    "            formant_1_w, formant_2_w, formant_3_w = find_formants_across_frames(w, h)\n",
    "\n",
    "            formant_1_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_1_w]\n",
    "            formant_2_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_2_w]\n",
    "            formant_3_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_3_w]\n",
    "\n",
    "            frame_features = []\n",
    "            for f1, f2, f3 in zip(formant_1_Hz, formant_2_Hz, formant_3_Hz):\n",
    "                if f1 is not None and f2 is not None and f3 is not None:\n",
    "                    frame_features.append([f1, f2, f3])\n",
    "\n",
    "            if not frame_features:\n",
    "                continue\n",
    "\n",
    "            frame_features_df = pd.DataFrame(frame_features, columns=['Formant_1_Hz', 'Formant_2_Hz', 'Formant_3_Hz'])\n",
    "            predicted_vowels = model.predict(frame_features_df)\n",
    "            predicted_vowels = le.inverse_transform(predicted_vowels.astype(int))\n",
    "\n",
    "            predicted_vowel, count = np.unique(predicted_vowels, return_counts=True)\n",
    "            classified_vowel = predicted_vowel[np.argmax(count)]\n",
    "\n",
    "            actual_vowel = extract_vowel_from_filename(filename)\n",
    "            results.append((filename, actual_vowel, classified_vowel))\n",
    "\n",
    "    df_results = pd.DataFrame(results, columns=[\"Filename\", \"Actual Vowel\", \"Predicted Vowel\"])\n",
    "    df_results.to_csv(output_csv, index=False)\n",
    "    print(f\"Predicted vowels saved to {output_csv}\")\n",
    "\n",
    "    correct_predictions = df_results[df_results['Actual Vowel'] == df_results['Predicted Vowel']].shape[0]\n",
    "    total_predictions = df_results.shape[0]\n",
    "    accuracy = (correct_predictions / total_predictions) * 100\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Example usage\n",
    "input_folder = r\"Vowel_recordings\"\n",
    "output_csv = r\"vowel_formant_features.csv\"\n",
    "process_folder(input_folder, output_csv)\n",
    "\n",
    "rfc, le = train_random_forest(output_csv)\n",
    "classify_files(input_folder, rfc, le)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5fbe25a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to vowel_formant_features.csv\n",
      "Train accuracy: 0.71\n",
      "Test accuracy: 0.70\n",
      "Cross-validation accuracy: 0.69 (+/- 0.01)\n",
      "Predicted vowels saved to predicted_vowels.csv\n",
      "Accuracy: 99.33%\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from scipy.signal import freqz\n",
    "import peakutils\n",
    "from sidekit.frontend.features import plp\n",
    "import pickle\n",
    "\n",
    "def read_samples_from_txt(file_path):\n",
    "    samples = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            samples.extend([float(value) for value in line.strip().split()])\n",
    "    return np.array(samples)\n",
    "\n",
    "def extract_plp_features(samples, sampling_rate=16000, rasta=False, plp_order=10):\n",
    "    try:\n",
    "        lpcas = plp(samples, fs=sampling_rate, rasta=rasta, plp_order=plp_order)\n",
    "        return lpcas\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting PLP features: {e}\")\n",
    "        return None\n",
    "\n",
    "def compute_lpc_filter_and_response(lpc_coeffs):\n",
    "    if lpc_coeffs is None:\n",
    "        raise ValueError(\"LPC coefficients are not provided.\")\n",
    "    \n",
    "    if isinstance(lpc_coeffs, (list, np.ndarray)):\n",
    "        lpc_coeffs = np.array(lpc_coeffs)\n",
    "        if lpc_coeffs.ndim != 2:\n",
    "            raise ValueError(\"LPC coefficients must be a 2D array (frames x order).\")\n",
    "    \n",
    "    num_frames, num_order = lpc_coeffs.shape\n",
    "    all_w = []\n",
    "    all_h = []\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        lpc_filter = np.concatenate(([1], -lpc_coeffs[i]))\n",
    "        w, h = freqz(lpc_filter)\n",
    "        all_w.append(w)\n",
    "        all_h.append(h)\n",
    "    \n",
    "    all_w = np.array(all_w)\n",
    "    all_h = np.array(all_h)\n",
    "    \n",
    "    return all_w, all_h\n",
    "\n",
    "def find_formants_across_frames(w, h):\n",
    "    formant_1_w = []\n",
    "    formant_2_w = []\n",
    "    formant_3_w = []\n",
    "    \n",
    "    for i in range(w.shape[0]):\n",
    "        h_db = 20 * np.log10(np.abs(h[i]))\n",
    "        peak_indices = peakutils.indexes(h_db)\n",
    "\n",
    "        if peak_indices.size > 2:\n",
    "            formant_1_w.append(w[i][peak_indices[0]])\n",
    "            formant_2_w.append(w[i][peak_indices[1]])\n",
    "            formant_3_w.append(w[i][peak_indices[2]])\n",
    "        else:\n",
    "            formant_1_w.append(None)\n",
    "            formant_2_w.append(None)\n",
    "            formant_3_w.append(None)\n",
    "    \n",
    "    return formant_1_w, formant_2_w, formant_3_w\n",
    "\n",
    "def extract_vowel_from_filename(filename):\n",
    "    match = re.search(r'[a-zA-Z]', filename)\n",
    "    if match:\n",
    "        return match.group().lower()\n",
    "    return None\n",
    "\n",
    "def process_folder(input_folder, output_csv, sampling_rate=16000):\n",
    "    data = []\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            samples = read_samples_from_txt(file_path)\n",
    "            \n",
    "            lpcas = extract_plp_features(samples, sampling_rate=sampling_rate)\n",
    "            if lpcas is None:\n",
    "                continue\n",
    "\n",
    "            w, h = compute_lpc_filter_and_response(lpcas)\n",
    "\n",
    "            formant_1_w, formant_2_w, formant_3_w = find_formants_across_frames(w, h)\n",
    "\n",
    "            formant_1_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_1_w]\n",
    "            formant_2_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_2_w]\n",
    "            formant_3_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_3_w]\n",
    "\n",
    "            vowel = extract_vowel_from_filename(filename)\n",
    "            if vowel is None:\n",
    "                print(f\"Could not extract vowel from {filename}\")\n",
    "                continue\n",
    "\n",
    "            for f1, f2, f3 in zip(formant_1_Hz, formant_2_Hz, formant_3_Hz):\n",
    "                if f1 is not None and f2 is not None and f3 is not None:\n",
    "                    data.append([f1, f2, f3, vowel])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['Formant_1_Hz', 'Formant_2_Hz', 'Formant_3_Hz', 'Vowel'])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Features saved to {output_csv}\")\n",
    "\n",
    "def train_random_forest(output_csv):\n",
    "    df = pd.read_csv(output_csv)\n",
    "    le = LabelEncoder()\n",
    "    df['Vowel_Encoded'] = le.fit_transform(df['Vowel'])\n",
    "    X = df[['Formant_1_Hz', 'Formant_2_Hz', 'Formant_3_Hz']]\n",
    "    y = df['Vowel_Encoded']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Using the given hyperparameters directly\n",
    "    best_params = {\n",
    "        'max_depth': 5,\n",
    "        'max_features': 'auto',\n",
    "        'min_samples_leaf': 1,\n",
    "        'min_samples_split': 5,\n",
    "        'n_estimators': 100\n",
    "    }\n",
    "\n",
    "    rfc = RandomForestClassifier(random_state=42, **best_params)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model performance\n",
    "    train_accuracy = rfc.score(X_train, y_train)\n",
    "    test_accuracy = rfc.score(X_test, y_test)\n",
    "    print(f\"Train accuracy: {train_accuracy:.2f}\")\n",
    "    print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(rfc, X, y, cv=5)\n",
    "    print(f\"Cross-validation accuracy: {cv_scores.mean():.2f} (+/- {cv_scores.std():.2f})\")\n",
    "\n",
    "    # Save the model and label encoder\n",
    "    with open('vowel_classifier_model.pkl', 'wb') as f:\n",
    "        pickle.dump((rfc, le), f)\n",
    "\n",
    "    return rfc, le\n",
    "\n",
    "def classify_files(input_folder, model, le, sampling_rate=16000, output_csv=\"predicted_vowels.csv\"):\n",
    "    results = []\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            samples = read_samples_from_txt(file_path)\n",
    "            \n",
    "            lpcas = extract_plp_features(samples, sampling_rate=sampling_rate)\n",
    "            if lpcas is None:\n",
    "                continue\n",
    "\n",
    "            w, h = compute_lpc_filter_and_response(lpcas)\n",
    "\n",
    "            formant_1_w, formant_2_w, formant_3_w = find_formants_across_frames(w, h)\n",
    "\n",
    "            formant_1_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_1_w]\n",
    "            formant_2_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_2_w]\n",
    "            formant_3_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_3_w]\n",
    "\n",
    "            frame_features = []\n",
    "            for f1, f2, f3 in zip(formant_1_Hz, formant_2_Hz, formant_3_Hz):\n",
    "                if f1 is not None and f2 is not None and f3 is not None:\n",
    "                    frame_features.append([f1, f2, f3])\n",
    "\n",
    "            if not frame_features:\n",
    "                continue\n",
    "\n",
    "            frame_features_df = pd.DataFrame(frame_features, columns=['Formant_1_Hz', 'Formant_2_Hz', 'Formant_3_Hz'])\n",
    "            predicted_vowels = model.predict(frame_features_df)\n",
    "            predicted_vowels = le.inverse_transform(predicted_vowels.astype(int))\n",
    "\n",
    "            predicted_vowel, count = np.unique(predicted_vowels, return_counts=True)\n",
    "            classified_vowel = predicted_vowel[np.argmax(count)]\n",
    "\n",
    "            actual_vowel = extract_vowel_from_filename(filename)\n",
    "            results.append((filename, actual_vowel, classified_vowel))\n",
    "\n",
    "    df_results = pd.DataFrame(results, columns=[\"Filename\", \"Actual Vowel\", \"Predicted Vowel\"])\n",
    "    df_results.to_csv(output_csv, index=False)\n",
    "    print(f\"Predicted vowels saved to {output_csv}\")\n",
    "\n",
    "    correct_predictions = df_results[df_results['Actual Vowel'] == df_results['Predicted Vowel']].shape[0]\n",
    "    total_predictions = df_results.shape[0]\n",
    "    accuracy = (correct_predictions / total_predictions) * 100\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Example usage\n",
    "input_folder = r\"Vowel_recordings\"\n",
    "output_csv = r\"vowel_formant_features.csv\"\n",
    "process_folder(input_folder, output_csv)\n",
    "\n",
    "rfc, le = train_random_forest(output_csv)\n",
    "classify_files(input_folder, rfc, le)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0449385a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording complete\n",
      "Predicted Vowel: u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tsriv\\AppData\\Roaming\\Python\\Python39\\site-packages\\sidekit\\frontend\\features.py:389: RuntimeWarning: divide by zero encountered in log\n",
      "  log_energy = numpy.log((framed**2).sum(axis=1))\n",
      "C:\\Users\\tsriv\\AppData\\Roaming\\Python\\Python39\\site-packages\\sidekit\\frontend\\features.py:1092: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  temp = -save / P\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.signal import freqz\n",
    "import peakutils\n",
    "from sidekit.frontend.features import plp\n",
    "\n",
    "\n",
    "\n",
    "# Load the model and label encoder\n",
    "with open('vowel_classifier_model.pkl', 'rb') as f:\n",
    "    rfc, le = pickle.load(f)\n",
    "\n",
    "def record_audio(duration, fs):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='float64')\n",
    "    sd.wait()\n",
    "    print(\"Recording complete\")\n",
    "    audio = audio.flatten()\n",
    "    return audio\n",
    "\n",
    "def trim_audio(audio, fs, threshold):\n",
    "    max_amplitude = np.max(np.abs(audio))\n",
    "    amplitude_threshold = threshold * max_amplitude\n",
    "    audio[np.abs(audio) < amplitude_threshold] = 0\n",
    "    start_idx = np.argmax(audio > amplitude_threshold)\n",
    "    end_idx = len(audio) - np.argmax(audio[::-1] > amplitude_threshold)\n",
    "    return audio[start_idx:end_idx]\n",
    "\n",
    "def predict_vowel(audio, fs, model, le):\n",
    "    lpcas = extract_plp_features(audio, sampling_rate=fs)\n",
    "    if lpcas is None:\n",
    "        return None\n",
    "\n",
    "    w, h = compute_lpc_filter_and_response(lpcas)\n",
    "    formant_1_w, formant_2_w, formant_3_w = find_formants_across_frames(w, h)\n",
    "\n",
    "    formant_1_Hz = [(x * fs) / (2 * np.pi) if x is not None else None for x in formant_1_w]\n",
    "    formant_2_Hz = [(x * fs) / (2 * np.pi) if x is not None else None for x in formant_2_w]\n",
    "    formant_3_Hz = [(x * fs) / (2 * np.pi) if x is not None else None for x in formant_3_w]\n",
    "\n",
    "    frame_features = []\n",
    "    for f1, f2, f3 in zip(formant_1_Hz, formant_2_Hz, formant_3_Hz):\n",
    "        if f1 is not None and f2 is not None and f3 is not None:\n",
    "            frame_features.append([f1, f2, f3])\n",
    "\n",
    "    if not frame_features:\n",
    "        return None\n",
    "\n",
    "    frame_features_df = pd.DataFrame(frame_features, columns=['Formant_1_Hz', 'Formant_2_Hz', 'Formant_3_Hz'])\n",
    "    predicted_vowels = model.predict(frame_features_df)\n",
    "    predicted_vowels = le.inverse_transform(predicted_vowels.astype(int))\n",
    "\n",
    "    predicted_vowel, count = np.unique(predicted_vowels, return_counts=True)\n",
    "    return predicted_vowel[np.argmax(count)]\n",
    "\n",
    "# Parameters\n",
    "duration = 5  # seconds\n",
    "fs = 16000  # sampling rate\n",
    "threshold = 0.01\n",
    "\n",
    "# Record and trim audio\n",
    "audio = record_audio(duration, fs)\n",
    "trimmed_audio = trim_audio(audio, fs, threshold)\n",
    "\n",
    "# Predict vowel\n",
    "\n",
    "predicted_vowel = predict_vowel(trimmed_audio, fs, rfc, le)\n",
    "print(f\"Predicted Vowel: {predicted_vowel}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9be611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de99a623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
